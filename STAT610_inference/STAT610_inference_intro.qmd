---
title: "STAT 610 ‚Äì Introduction to Statistical Inference (Bootcamp)"
author: "Dr. Mighty Itauma"
format:
  html:
    toc: true
    code-fold: true
    df-print: paged
jupyter: python3
---

## Simulation of LLN and CLT for Systolic Blood Pressure

```{python}
import numpy as np
import matplotlib.pyplot as plt

np.random.seed(42)

# Suppose true systolic BP in a population ~ Normal(120, 15^2)
mu = 120
sigma = 15

def simulate_sample_means(n, n_rep=5000):
    means = []
    for _ in range(n_rep):
        sample = np.random.normal(mu, sigma, size=n)
        means.append(np.mean(sample))
    return np.array(means)

sample_sizes = [5, 20, 100]

for n in sample_sizes:
    means = simulate_sample_means(n)
    print(f"n = {n}: mean of sample means = {means.mean():.2f}, sd = {means.std():.2f}")
    
    plt.figure()
    plt.hist(means, bins=40, density=True)
    plt.title(f"Sampling distribution of mean SBP (n={n})")
    plt.xlabel("Sample mean SBP")
    plt.ylabel("Density")
    plt.show()

```


## Comparing Estimators: Sample Mean vs First Observation

```{python}
import numpy as np

np.random.seed(123)

mu = 120
sigma = 15
n = 10          # sample size
n_rep = 10000   # number of simulations

means = []
first_obs = []

for _ in range(n_rep):
    sample = np.random.normal(mu, sigma, size=n)
    means.append(np.mean(sample))
    first_obs.append(sample[0])

means = np.array(means)
first_obs = np.array(first_obs)

# Compute empirical bias, variance, and MSE
def summarize(estimates, true):
    bias = np.mean(estimates) - true
    var = np.var(estimates, ddof=0)
    mse = np.mean((estimates - true)**2)
    return bias, var, mse

bias_mean, var_mean, mse_mean = summarize(means, mu)
bias_first, var_first, mse_first = summarize(first_obs, mu)

print("Sample mean estimator:")
print(f"  Bias = {bias_mean:.3f}")
print(f"  Var  = {var_mean:.3f}")
print(f"  MSE  = {mse_mean:.3f}")

print("\nFirst observation estimator:")
print(f"  Bias = {bias_first:.3f}")
print(f"  Var  = {var_first:.3f}")
print(f"  MSE  = {mse_first:.3f}")

```

## Confidence Interval Simulation for Systolic BP

```{python}
import numpy as np
from scipy.stats import t

np.random.seed(42)

mu = 120
sigma = 15
n = 25
n_rep = 5000

lower_bounds = []
upper_bounds = []

for _ in range(n_rep):
    sample = np.random.normal(mu, sigma, size=n)
    xbar = np.mean(sample)
    s = np.std(sample, ddof=1)
    t_crit = t.ppf(0.975, df=n-1)
    
    lower = xbar - t_crit * s / np.sqrt(n)
    upper = xbar + t_crit * s / np.sqrt(n)
    
    lower_bounds.append(lower)
    upper_bounds.append(upper)

# Coverage probability
coverage = np.mean([1 if lb <= mu <= ub else 0 for lb, ub in zip(lower_bounds, upper_bounds)])
print(f"Empirical coverage probability ‚âà {coverage:.3f}")

```

The small difference between 0.947 and the theoretical 0.950 is expected due to random sampling variability. 

## Power to Detect a 5 mmHg Reduction in SBP

```{python}
import numpy as np
from scipy.stats import t

np.random.seed(123)

mu0 = 120     # null mean
mu1 = 115     # true mean under alternative
sigma = 15
n = 80        # try sample size 40
alpha = 0.05
n_rep = 5000

rejects = 0

for _ in range(n_rep):
    sample = np.random.normal(mu1, sigma, size=n)
    xbar = np.mean(sample)
    s = np.std(sample, ddof=1)
    
    t_stat = (xbar - mu0) / (s / np.sqrt(n))
    t_crit = t.ppf(1 - alpha/2, df=n-1)
    
    if abs(t_stat) > t_crit:
        rejects += 1

power = rejects / n_rep
print(f"Empirical power ‚âà {power:.3f}")

```

- n = 20: Empirical power ‚âà 0.284  
- n = 40: Empirical power ‚âà 0.530  
- n = 80: Empirical power ‚âà 0.836

## Estimating Fisher Information Numerically

```{python}
import numpy as np

def fisher_information_normal_known_sigma(sigma):
    return 1 / sigma**2

sigma = 15
I = fisher_information_normal_known_sigma(sigma)
print("Fisher Information for Œº:", I)

# Asymptotic variance of MLE for Œº
n = 200
asymp_var = 1 / (n * I)
print("Asymptotic variance of ŒºÃÇ:", asymp_var)
print("Asymptotic SE:", np.sqrt(asymp_var))

```

n = 100  
Fisher Information for Œº: 0.0044444444444444444  
Asymptotic variance of ŒºÃÇ: 2.25  
Asymptotic SE: 1.5  


n = 200  
Fisher Information for Œº: 0.0044444444444444444  
Asymptotic variance of ŒºÃÇ: 1.125  
Asymptotic SE: 1.0606601717798212  

As n increases, asymptotic SE decreases because variance shrinks at a rate of 
$1/ùëõ$.